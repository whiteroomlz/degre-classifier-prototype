{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ef8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7253178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5abe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "def load_datasets(lang, folder):\n",
    "    test = glob.glob(f'./{folder}/{lang}/test/*/*.csv')\n",
    "    train = glob.glob(f'./{folder}/{lang}/train/*/*.csv')\n",
    "    \n",
    "    error_titles = []\n",
    "    \n",
    "    features_test = []\n",
    "    part = 'test'\n",
    "    for title in tqdm(test, desc=part):\n",
    "        try:\n",
    "            txt_type = title[title.find('\\\\') + 1:title.rfind('\\\\')]\n",
    "            name = int(re.findall(r'\\d+', title)[0])    \n",
    "            ft = pd.read_csv(title, header=None).iloc[0]\n",
    "            ft['name'] = name\n",
    "            ft['text_type'] = txt_type\n",
    "            ft['part'] = part\n",
    "            features_test.append(ft)\n",
    "        except:\n",
    "            error_titles.append(title)\n",
    "            \n",
    "    features_train = []\n",
    "    part = 'train'\n",
    "    for title in tqdm(train, desc=part):\n",
    "        try:\n",
    "            txt_type = title[title.find('\\\\') + 1:title.rfind('\\\\')]\n",
    "            name = int(re.findall(r'\\d+', title)[0])    \n",
    "            ft = pd.read_csv(title, header=None).iloc[0]\n",
    "            ft['name'] = name\n",
    "            ft['text_type'] = txt_type\n",
    "            ft['part'] = part\n",
    "            features_train.append(ft)\n",
    "        except:\n",
    "            error_titles.append(title)\n",
    "            \n",
    "    features = pd.concat([\n",
    "        pd.DataFrame(features_test), pd.DataFrame(features_train)\n",
    "    ]).reset_index(drop=True)\n",
    "    \n",
    "    np.save(f'{folder}/{lang}_bad_files.npy', error_titles)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dbbc8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SVD results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef806c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd_datasets = {}\n",
    "for lang in tqdm(['rus', 'eng']):\n",
    "    svd_datasets[lang] = load_datasets(lang, 'svd_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('svd_datasets.npy', svd_datasets, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5dca1-bd8a-42f0-a9ba-6979c8a4eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_datasets = np.load('svd_datasets.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b819a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd_res = {}\n",
    "for lang in tqdm(['rus', 'eng']):\n",
    "    svd_res[lang] = full_pipeline(svd_datasets[lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('svd_results.npy', svd_res, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73b87b",
   "metadata": {},
   "source": [
    "## CBOW results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba9730-2375-4150-a44c-0fb47fe0c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_datasets = {}\n",
    "for lang in tqdm(['rus', 'eng']):\n",
    "    cbow_datasets[lang] = load_datasets(lang, 'cbow_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cbow_datasets.npy', cbow_datasets, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_datasets = np.load('cbow_datasets.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef35c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_res = {}\n",
    "for lang in tqdm(['rus', 'eng']):\n",
    "    cbow_res[lang] = full_pipeline(cbow_datasets[lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d09d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cbow_results.npy', cbow_res, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8c886-0f3a-4dd7-bada-5e7e66bf4123",
   "metadata": {
    "tags": []
   },
   "source": [
    "## best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38e1de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147b08b8-05f5-4ed2-8790-603358eedc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = {\n",
    "    'svd': np.load('svd_results.npy', allow_pickle=True).item(), \n",
    "    'cbow': np.load('cbow_results.npy', allow_pickle=True).item(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35f1a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'svd': np.load('svd_datasets.npy', allow_pickle=True).item(),\n",
    "    'cbow': np.load('cbow_datasets.npy', allow_pickle=True).item()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeeef064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, accuracy\n",
      "\n",
      "emb\trus\teng\n",
      "\n",
      "svd\t0.64\t0.79\t\n",
      "cbow\t0.51\t0.61\t"
     ]
    }
   ],
   "source": [
    "print('Random Forest, accuracy')\n",
    "print('emb', *list(res['svd'].keys()), sep='\\t')\n",
    "\n",
    "for emb_type in ['svd', 'cbow']:\n",
    "    print(emb_type, end='\\t')\n",
    "    for lang in res[emb_type].keys():\n",
    "        test_label = datasets[emb_type][lang].query('part == \\'test\\'').text_type == 'lit'\n",
    "        test_ft = datasets[emb_type][lang].query('part == \\'test\\'').drop(columns=['name', 'text_type', 'part'])\n",
    "\n",
    "        rf_model = res[emb_type][lang]['random_forest']['model']\n",
    "        test_predict = rf_model.predict(test_ft)\n",
    "\n",
    "        s = accuracy_score(test_label, test_predict)\n",
    "        print(\"%.2f\" % s, end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "405d1ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, f1 score\n",
      "\n",
      "emb\trus\teng\n",
      "\n",
      "svd\t0.68\t0.79\t\n",
      "cbow\t0.05\t0.56\t"
     ]
    }
   ],
   "source": [
    "print('Random Forest, f1 score')\n",
    "print('emb', *list(res['svd'].keys()), sep='\\t')\n",
    "\n",
    "for emb_type in ['svd', 'cbow']:\n",
    "    print(emb_type, end='\\t')\n",
    "    for lang in res[emb_type].keys():\n",
    "        test_label = datasets[emb_type][lang].query('part == \\'test\\'').text_type == 'lit'\n",
    "        test_ft = datasets[emb_type][lang].query('part == \\'test\\'').drop(columns=['name', 'text_type', 'part'])\n",
    "\n",
    "        rf_model = res[emb_type][lang]['random_forest']['model']\n",
    "        test_predict = rf_model.predict(test_ft)\n",
    "\n",
    "        s = f1_score(test_label, test_predict)\n",
    "        print(\"%.2f\" % s, end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dcbd633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree, accuracy\n",
      "\n",
      "emb\trus\teng\n",
      "\n",
      "svd\t0.61\t0.78\t\n",
      "cbow\t0.50\t0.58\t"
     ]
    }
   ],
   "source": [
    "print('Decision tree, accuracy')\n",
    "print('emb', *list(res['svd'].keys()), sep='\\t')\n",
    "\n",
    "for emb_type in ['svd', 'cbow']:\n",
    "    print(emb_type, end='\\t')\n",
    "    for lang in res[emb_type].keys():\n",
    "        test_label = datasets[emb_type][lang].query('part == \\'test\\'').text_type == 'lit'\n",
    "        test_ft = datasets[emb_type][lang].query('part == \\'test\\'').drop(columns=['name', 'text_type', 'part'])\n",
    "\n",
    "        rf_model = res[emb_type][lang]['decision_tree']['model']\n",
    "        test_predict = rf_model.predict(test_ft)\n",
    "\n",
    "        s = accuracy_score(test_label, test_predict)\n",
    "        print(\"%.2f\" % s, end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ecf2161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree, f1 score\n",
      "\n",
      "emb\trus\teng\n",
      "\n",
      "svd\t0.66\t0.78\t\n",
      "cbow\t0.02\t0.58\t"
     ]
    }
   ],
   "source": [
    "print('Decision tree, f1 score')\n",
    "print('emb', *list(res['svd'].keys()), sep='\\t')\n",
    "\n",
    "for emb_type in ['svd', 'cbow']:\n",
    "    print(emb_type, end='\\t')\n",
    "    for lang in res[emb_type].keys():\n",
    "        test_label = datasets[emb_type][lang].query('part == \\'test\\'').text_type == 'lit'\n",
    "        test_ft = datasets[emb_type][lang].query('part == \\'test\\'').drop(columns=['name', 'text_type', 'part'])\n",
    "\n",
    "        rf_model = res[emb_type][lang]['decision_tree']['model']\n",
    "        test_predict = rf_model.predict(test_ft)\n",
    "\n",
    "        s = f1_score(test_label, test_predict)\n",
    "        print(\"%.2f\" % s, end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4986eaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVC tree, accuracy\n",
      "\n",
      "emb\trus\teng\n",
      "\n",
      "svd\t0.54\t0.42\t\n",
      "cbow\t0.50\t0.63\t"
     ]
    }
   ],
   "source": [
    "print('LSVC tree, accuracy')\n",
    "print('emb', *list(res['svd'].keys()), sep='\\t')\n",
    "\n",
    "for emb_type in ['svd', 'cbow']:\n",
    "    print(emb_type, end='\\t')\n",
    "    for lang in res[emb_type].keys():\n",
    "        test_label = datasets[emb_type][lang].query('part == \\'test\\'').text_type == 'lit'\n",
    "        test_ft = datasets[emb_type][lang].query('part == \\'test\\'').drop(columns=['name', 'text_type', 'part'])\n",
    "\n",
    "        rf_model = res[emb_type][lang]['lsvc']['model']\n",
    "        test_predict = rf_model.predict(test_ft)\n",
    "\n",
    "        s = accuracy_score(test_label, test_predict)\n",
    "        print(\"%.2f\" % s, end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47483382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVC tree, f1 score\n",
      "\n",
      "emb\trus\teng\n",
      "\n",
      "svd\t0.52\t0.50\t\n",
      "cbow\t0.00\t0.59\t"
     ]
    }
   ],
   "source": [
    "print('LSVC tree, f1 score')\n",
    "print('emb', *list(res['svd'].keys()), sep='\\t')\n",
    "\n",
    "for emb_type in ['svd', 'cbow']:\n",
    "    print(emb_type, end='\\t')\n",
    "    for lang in res[emb_type].keys():\n",
    "        test_label = datasets[emb_type][lang].query('part == \\'test\\'').text_type == 'lit'\n",
    "        test_ft = datasets[emb_type][lang].query('part == \\'test\\'').drop(columns=['name', 'text_type', 'part'])\n",
    "\n",
    "        rf_model = res[emb_type][lang]['lsvc']['model']\n",
    "        test_predict = rf_model.predict(test_ft)\n",
    "\n",
    "        s = f1_score(test_label, test_predict)\n",
    "        print(\"%.2f\" % s, end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49947eea-be49-4e95-a4af-7f186acf4219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
